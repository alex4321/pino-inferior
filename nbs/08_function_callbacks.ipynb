{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp function_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Union, Callable, Awaitable\n",
    "from uuid import UUID\n",
    "from langchain.callbacks.base import AsyncCallbackHandler\n",
    "from langchain.schema.messages import BaseMessage\n",
    "from langchain.schema.output import ChatGenerationChunk, GenerationChunk, LLMResult\n",
    "from enum import Enum\n",
    "import asyncio\n",
    "from traceback import format_exception\n",
    "from pino_inferior.core import OPENAI_API_KEY\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LLMEventType(Enum):\n",
    "    LLM_START = \"LLM_START\"\n",
    "    LLM_TOKEN = \"TOKEN\"\n",
    "    LLM_ERROR = \"LLM_ERROR\"\n",
    "    LLM_END = \"LLM_END\"\n",
    "\n",
    "\n",
    "AsyncLLMCallback = Callable[[LLMEventType, datetime, str], Awaitable[None]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AsyncFunctionalStyleChatCompletionHandler(AsyncCallbackHandler):\n",
    "    def __init__(self, callback: AsyncLLMCallback) -> None:\n",
    "        super().__init__()\n",
    "        self.llm_callback = callback\n",
    "    \n",
    "    async def on_llm_start(self,\n",
    "                           serialized: Dict[str, Any],\n",
    "                           prompts: List[str],\n",
    "                           *,\n",
    "                           run_id: UUID,\n",
    "                           parent_run_id: UUID | None = None,\n",
    "                           tags: List[str] | None = None,\n",
    "                           metadata: Dict[str, Any] | None = None,\n",
    "                           **kwargs: Any) -> None:\n",
    "        assert len(prompts) == 1, \"This agent structure works with 1 query each time\"\n",
    "        time = datetime.now()\n",
    "        await asyncio.gather(*[\n",
    "            self.llm_callback(\n",
    "                LLMEventType.LLM_START,\n",
    "                time,\n",
    "                prompt\n",
    "            )\n",
    "            for prompt in prompts\n",
    "        ])\n",
    "    \n",
    "    async def on_chat_model_start(self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], *, run_id: UUID, parent_run_id: UUID | None = None, tags: List[str] | None = None, metadata: Dict[str, Any] | None = None, **kwargs: Any) -> Any:\n",
    "        prompts = [\n",
    "            \"\\n\\n\".join([\n",
    "                f\"{message.type}: {message.content}\"\n",
    "                for message in thread\n",
    "            ])\n",
    "            for thread in messages\n",
    "        ]\n",
    "        await self.on_llm_start(serialized, prompts, run_id=run_id, parent_run_id=parent_run_id, tags=tags, metadata=metadata, **kwargs)\n",
    "    \n",
    "    async def on_llm_new_token(self, token: str, *, chunk: GenerationChunk | ChatGenerationChunk | None = None, run_id: UUID, parent_run_id: UUID | None = None, tags: List[str] | None = None, **kwargs: Any) -> None:\n",
    "        await self.llm_callback(LLMEventType.LLM_TOKEN, datetime.now(), token)\n",
    "    \n",
    "    async def on_llm_end(self, response: LLMResult, *, run_id: UUID, parent_run_id: UUID | None = None, tags: List[str] | None = None, **kwargs: Any) -> None:\n",
    "        assert len(response.generations) == 1, \"This agent implementation works with 1 generated response\"\n",
    "        assert len(response.generations[0]) == 1, \"This agent implementation works with 1 generated response\"\n",
    "        text = response.generations[0][0].text\n",
    "        await self.llm_callback(\n",
    "            LLMEventType.LLM_END,\n",
    "            datetime.now(),\n",
    "            text,\n",
    "        )\n",
    "    \n",
    "    async def on_llm_error(self, error: BaseException, *, run_id: UUID, parent_run_id: UUID | None = None, tags: List[str] | None = None, **kwargs: Any) -> None:\n",
    "        await self.llm_callback(\n",
    "            LLMEventType.LLM_ERROR,\n",
    "            datetime.now(),\n",
    "            \"\".join(format_exception(error)),\n",
    "        )\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_START 2023-11-08 00:41:02.474656 human: Tell me what is (2+2) * 2. Think step by step\n",
      "_completion_with_retry {'messages': [{'role': 'user', 'content': 'Tell me what is (2+2) * 2. Think step by step'}], 'model': 'gpt-3.5-turbo', 'request_timeout': None, 'max_tokens': None, 'stream': True, 'n': 1, 'temperature': 0.7, 'api_key': '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', 'api_base': '', 'organization': ''}\n",
      "TOKEN 2023-11-08 00:41:03.313383 \n",
      "TOKEN 2023-11-08 00:41:03.315638 To\n",
      "TOKEN 2023-11-08 00:41:03.322724  solve\n",
      "TOKEN 2023-11-08 00:41:03.353727  (\n",
      "TOKEN 2023-11-08 00:41:03.368723 2\n",
      "TOKEN 2023-11-08 00:41:03.385724 +\n",
      "TOKEN 2023-11-08 00:41:03.413130 2\n",
      "TOKEN 2023-11-08 00:41:03.416131 )\n",
      "TOKEN 2023-11-08 00:41:03.431058  *\n",
      "TOKEN 2023-11-08 00:41:03.457078  \n",
      "TOKEN 2023-11-08 00:41:03.479733 2\n",
      "TOKEN 2023-11-08 00:41:03.491756  step\n",
      "TOKEN 2023-11-08 00:41:03.510005  by\n",
      "TOKEN 2023-11-08 00:41:03.527917  step\n",
      "TOKEN 2023-11-08 00:41:03.540580 ,\n",
      "TOKEN 2023-11-08 00:41:03.588207  follow\n",
      "TOKEN 2023-11-08 00:41:03.592736  the\n",
      "TOKEN 2023-11-08 00:41:03.608847  order\n",
      "TOKEN 2023-11-08 00:41:03.629793  of\n",
      "TOKEN 2023-11-08 00:41:03.642794  operations\n",
      "TOKEN 2023-11-08 00:41:03.657822 :\n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:03.707834 1\n",
      "TOKEN 2023-11-08 00:41:03.708835 .\n",
      "TOKEN 2023-11-08 00:41:03.793601  Start\n",
      "TOKEN 2023-11-08 00:41:03.796600  with\n",
      "TOKEN 2023-11-08 00:41:03.797601  the\n",
      "TOKEN 2023-11-08 00:41:03.798599  parentheses\n",
      "TOKEN 2023-11-08 00:41:03.799598 ,\n",
      "TOKEN 2023-11-08 00:41:03.857603  (\n",
      "TOKEN 2023-11-08 00:41:03.858604 2\n",
      "TOKEN 2023-11-08 00:41:03.859603 +\n",
      "TOKEN 2023-11-08 00:41:03.862604 2\n",
      "TOKEN 2023-11-08 00:41:03.880618 ),\n",
      "TOKEN 2023-11-08 00:41:03.895203  which\n",
      "TOKEN 2023-11-08 00:41:03.937785  equals\n",
      "TOKEN 2023-11-08 00:41:03.962203  \n",
      "TOKEN 2023-11-08 00:41:03.971583 4\n",
      "TOKEN 2023-11-08 00:41:03.987581 .\n",
      "\n",
      "TOKEN 2023-11-08 00:41:04.004017   \n",
      "TOKEN 2023-11-08 00:41:04.022028  -\n",
      "TOKEN 2023-11-08 00:41:04.040451  (\n",
      "TOKEN 2023-11-08 00:41:04.056763 2\n",
      "TOKEN 2023-11-08 00:41:04.075927 +\n",
      "TOKEN 2023-11-08 00:41:04.088928 2\n",
      "TOKEN 2023-11-08 00:41:04.105928 )\n",
      "TOKEN 2023-11-08 00:41:04.124222  =\n",
      "TOKEN 2023-11-08 00:41:04.141941  \n",
      "TOKEN 2023-11-08 00:41:04.173943 4\n",
      "TOKEN 2023-11-08 00:41:04.192942 \n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:04.209942 2\n",
      "TOKEN 2023-11-08 00:41:04.223941 .\n",
      "TOKEN 2023-11-08 00:41:04.253942  Now\n",
      "TOKEN 2023-11-08 00:41:04.254942 ,\n",
      "TOKEN 2023-11-08 00:41:04.304940  rewrite\n",
      "TOKEN 2023-11-08 00:41:04.319941  the\n",
      "TOKEN 2023-11-08 00:41:04.334942  equation\n",
      "TOKEN 2023-11-08 00:41:04.360941  as\n",
      "TOKEN 2023-11-08 00:41:04.396941  \n",
      "TOKEN 2023-11-08 00:41:04.418941 4\n",
      "TOKEN 2023-11-08 00:41:04.428944  *\n",
      "TOKEN 2023-11-08 00:41:04.450941  \n",
      "TOKEN 2023-11-08 00:41:04.467942 2\n",
      "TOKEN 2023-11-08 00:41:04.487941 .\n",
      "\n",
      "TOKEN 2023-11-08 00:41:04.501942   \n",
      "TOKEN 2023-11-08 00:41:04.519941  -\n",
      "TOKEN 2023-11-08 00:41:04.535944  (\n",
      "TOKEN 2023-11-08 00:41:04.552943 2\n",
      "TOKEN 2023-11-08 00:41:04.583941 +\n",
      "TOKEN 2023-11-08 00:41:04.597941 2\n",
      "TOKEN 2023-11-08 00:41:04.636941 )\n",
      "TOKEN 2023-11-08 00:41:04.653941  *\n",
      "TOKEN 2023-11-08 00:41:04.670940  \n",
      "TOKEN 2023-11-08 00:41:04.688941 2\n",
      "TOKEN 2023-11-08 00:41:04.704941  =\n",
      "TOKEN 2023-11-08 00:41:04.720942  \n",
      "TOKEN 2023-11-08 00:41:04.738941 4\n",
      "TOKEN 2023-11-08 00:41:04.873940  *\n",
      "TOKEN 2023-11-08 00:41:04.875941  \n",
      "TOKEN 2023-11-08 00:41:04.875941 2\n",
      "TOKEN 2023-11-08 00:41:04.876941 \n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:04.877941 3\n",
      "TOKEN 2023-11-08 00:41:04.878941 .\n",
      "TOKEN 2023-11-08 00:41:04.879944  Multiply\n",
      "TOKEN 2023-11-08 00:41:04.880943  \n",
      "TOKEN 2023-11-08 00:41:04.887941 4\n",
      "TOKEN 2023-11-08 00:41:04.904942  by\n",
      "TOKEN 2023-11-08 00:41:04.933942  \n",
      "TOKEN 2023-11-08 00:41:04.936941 2\n",
      "TOKEN 2023-11-08 00:41:04.953942 .\n",
      "\n",
      "TOKEN 2023-11-08 00:41:04.966942   \n",
      "TOKEN 2023-11-08 00:41:04.983941  -\n",
      "TOKEN 2023-11-08 00:41:04.998941  \n",
      "TOKEN 2023-11-08 00:41:05.047944 4\n",
      "TOKEN 2023-11-08 00:41:05.086940  *\n",
      "TOKEN 2023-11-08 00:41:05.100944  \n",
      "TOKEN 2023-11-08 00:41:05.123041 2\n",
      "TOKEN 2023-11-08 00:41:05.137041  =\n",
      "TOKEN 2023-11-08 00:41:05.156040  \n",
      "TOKEN 2023-11-08 00:41:05.172037 8\n",
      "TOKEN 2023-11-08 00:41:05.189038 \n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:05.206038 Therefore\n",
      "TOKEN 2023-11-08 00:41:05.226038 ,\n",
      "TOKEN 2023-11-08 00:41:05.241041  (\n",
      "TOKEN 2023-11-08 00:41:05.259039 2\n",
      "TOKEN 2023-11-08 00:41:05.279037 +\n",
      "TOKEN 2023-11-08 00:41:05.296038 2\n",
      "TOKEN 2023-11-08 00:41:05.310037 )\n",
      "TOKEN 2023-11-08 00:41:05.452514  *\n",
      "TOKEN 2023-11-08 00:41:05.454510  \n",
      "TOKEN 2023-11-08 00:41:05.455509 2\n",
      "TOKEN 2023-11-08 00:41:05.456510  equals\n",
      "TOKEN 2023-11-08 00:41:05.457510  \n",
      "TOKEN 2023-11-08 00:41:05.457510 8\n",
      "TOKEN 2023-11-08 00:41:05.458510 .\n",
      "TOKEN 2023-11-08 00:41:05.459509 \n",
      "LLM_END 2023-11-08 00:41:05.460511 To solve (2+2) * 2 step by step, follow the order of operations:\n",
      "\n",
      "1. Start with the parentheses, (2+2), which equals 4.\n",
      "   - (2+2) = 4\n",
      "\n",
      "2. Now, rewrite the equation as 4 * 2.\n",
      "   - (2+2) * 2 = 4 * 2\n",
      "\n",
      "3. Multiply 4 by 2.\n",
      "   - 4 * 2 = 8\n",
      "\n",
      "Therefore, (2+2) * 2 equals 8.\n"
     ]
    }
   ],
   "source": [
    "async def _callback(event: LLMEventType, time: datetime, text: str) -> None:\n",
    "    print(f\"{event.value} {time} {text}\")\n",
    "\n",
    "\n",
    "callback = AsyncFunctionalStyleChatCompletionHandler(_callback)\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, callbacks=[callback], streaming=True)\n",
    "for token in model.stream([HumanMessage(content=\"Tell me what is (2+2) * 2. Think step by step\")]):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_START 2023-11-08 00:41:05.467323 human: Tell me what is (2+2) * 2. Think step by step\n",
      "_generate True\n",
      "_completion_with_retry {'messages': [{'role': 'user', 'content': 'Tell me what is (2+2) * 2. Think step by step'}], 'model': 'gpt-3.5-turbo', 'request_timeout': None, 'max_tokens': None, 'stream': True, 'n': 1, 'temperature': 0.7, 'api_key': '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', 'api_base': '', 'organization': ''}\n",
      "TOKEN 2023-11-08 00:41:06.441656 \n",
      "TOKEN 2023-11-08 00:41:06.443637 To\n",
      "TOKEN 2023-11-08 00:41:06.462808  solve\n",
      "TOKEN 2023-11-08 00:41:06.475679  the\n",
      "TOKEN 2023-11-08 00:41:06.497199  expression\n",
      "TOKEN 2023-11-08 00:41:06.510230  (\n",
      "TOKEN 2023-11-08 00:41:06.531216 2\n",
      "TOKEN 2023-11-08 00:41:06.551300 +\n",
      "TOKEN 2023-11-08 00:41:06.568955 2\n",
      "TOKEN 2023-11-08 00:41:06.588864 )\n",
      "TOKEN 2023-11-08 00:41:06.606869  *\n",
      "TOKEN 2023-11-08 00:41:06.625906  \n",
      "TOKEN 2023-11-08 00:41:06.644949 2\n",
      "TOKEN 2023-11-08 00:41:06.663189  step\n",
      "TOKEN 2023-11-08 00:41:06.684226  by\n",
      "TOKEN 2023-11-08 00:41:06.711829  step\n",
      "TOKEN 2023-11-08 00:41:06.741822 ,\n",
      "TOKEN 2023-11-08 00:41:06.751822  we\n",
      "TOKEN 2023-11-08 00:41:06.781860  follow\n",
      "TOKEN 2023-11-08 00:41:06.781860  the\n",
      "TOKEN 2023-11-08 00:41:06.792736  order\n",
      "TOKEN 2023-11-08 00:41:06.869840  of\n",
      "TOKEN 2023-11-08 00:41:06.870850  operations\n",
      "TOKEN 2023-11-08 00:41:06.873852 ,\n",
      "TOKEN 2023-11-08 00:41:06.907047  which\n",
      "TOKEN 2023-11-08 00:41:06.908058  is\n",
      "TOKEN 2023-11-08 00:41:06.923606  also\n",
      "TOKEN 2023-11-08 00:41:06.948106  known\n",
      "TOKEN 2023-11-08 00:41:06.971171  as\n",
      "TOKEN 2023-11-08 00:41:07.020862  PEM\n",
      "TOKEN 2023-11-08 00:41:07.067353 D\n",
      "TOKEN 2023-11-08 00:41:07.085002 AS\n",
      "TOKEN 2023-11-08 00:41:07.104349  (\n",
      "TOKEN 2023-11-08 00:41:07.123387 Paren\n",
      "TOKEN 2023-11-08 00:41:07.143462 theses\n",
      "TOKEN 2023-11-08 00:41:07.166985 ,\n",
      "TOKEN 2023-11-08 00:41:07.179218  Ex\n",
      "TOKEN 2023-11-08 00:41:07.202005 ponents\n",
      "TOKEN 2023-11-08 00:41:07.216223 ,\n",
      "TOKEN 2023-11-08 00:41:07.261944  Multip\n",
      "TOKEN 2023-11-08 00:41:07.265795 lication\n",
      "TOKEN 2023-11-08 00:41:07.279794  and\n",
      "TOKEN 2023-11-08 00:41:07.300678  Division\n",
      "TOKEN 2023-11-08 00:41:07.316694  from\n",
      "TOKEN 2023-11-08 00:41:07.335704  left\n",
      "TOKEN 2023-11-08 00:41:07.355538  to\n",
      "TOKEN 2023-11-08 00:41:07.376536  right\n",
      "TOKEN 2023-11-08 00:41:07.391984 ,\n",
      "TOKEN 2023-11-08 00:41:07.430468  Addition\n",
      "TOKEN 2023-11-08 00:41:07.436468  and\n",
      "TOKEN 2023-11-08 00:41:07.447475  Sub\n",
      "TOKEN 2023-11-08 00:41:07.467499 traction\n",
      "TOKEN 2023-11-08 00:41:07.485637  from\n",
      "TOKEN 2023-11-08 00:41:07.526094  left\n",
      "TOKEN 2023-11-08 00:41:07.533091  to\n",
      "TOKEN 2023-11-08 00:41:07.549543  right\n",
      "TOKEN 2023-11-08 00:41:07.566960 ).\n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:07.581026 1\n",
      "TOKEN 2023-11-08 00:41:07.599454 .\n",
      "TOKEN 2023-11-08 00:41:07.623241  First\n",
      "TOKEN 2023-11-08 00:41:07.646455 ,\n",
      "TOKEN 2023-11-08 00:41:07.674862  we\n",
      "TOKEN 2023-11-08 00:41:07.696209  evaluate\n",
      "TOKEN 2023-11-08 00:41:07.714821  the\n",
      "TOKEN 2023-11-08 00:41:07.731821  expression\n",
      "TOKEN 2023-11-08 00:41:07.754809  within\n",
      "TOKEN 2023-11-08 00:41:07.774810  the\n",
      "TOKEN 2023-11-08 00:41:07.829675  parentheses\n",
      "TOKEN 2023-11-08 00:41:07.841977 :\n",
      "TOKEN 2023-11-08 00:41:07.845979  (\n",
      "TOKEN 2023-11-08 00:41:07.858994 2\n",
      "TOKEN 2023-11-08 00:41:07.874003 +\n",
      "TOKEN 2023-11-08 00:41:07.890006 2\n",
      "TOKEN 2023-11-08 00:41:07.912465 )\n",
      "TOKEN 2023-11-08 00:41:07.930982  =\n",
      "TOKEN 2023-11-08 00:41:07.947689  \n",
      "TOKEN 2023-11-08 00:41:07.968321 4\n",
      "TOKEN 2023-11-08 00:41:07.987700 .\n",
      "\n",
      "TOKEN 2023-11-08 00:41:08.007717 2\n",
      "TOKEN 2023-11-08 00:41:08.033671 .\n",
      "TOKEN 2023-11-08 00:41:08.046674  Now\n",
      "TOKEN 2023-11-08 00:41:08.064001  the\n",
      "TOKEN 2023-11-08 00:41:08.082873  expression\n",
      "TOKEN 2023-11-08 00:41:08.150612  becomes\n",
      "TOKEN 2023-11-08 00:41:08.157613  \n",
      "TOKEN 2023-11-08 00:41:08.160613 4\n",
      "TOKEN 2023-11-08 00:41:08.170632  *\n",
      "TOKEN 2023-11-08 00:41:08.190065  \n",
      "TOKEN 2023-11-08 00:41:08.208079 2\n",
      "TOKEN 2023-11-08 00:41:08.235883 .\n",
      "\n",
      "TOKEN 2023-11-08 00:41:08.255106 3\n",
      "TOKEN 2023-11-08 00:41:08.275241 .\n",
      "TOKEN 2023-11-08 00:41:08.293748  Finally\n",
      "TOKEN 2023-11-08 00:41:08.315472 ,\n",
      "TOKEN 2023-11-08 00:41:08.331797  we\n",
      "TOKEN 2023-11-08 00:41:08.352060  multiply\n",
      "TOKEN 2023-11-08 00:41:08.373069  \n",
      "TOKEN 2023-11-08 00:41:08.402895 4\n",
      "TOKEN 2023-11-08 00:41:08.423884  by\n",
      "TOKEN 2023-11-08 00:41:08.442885  \n",
      "TOKEN 2023-11-08 00:41:08.466013 2\n",
      "TOKEN 2023-11-08 00:41:08.489431 :\n",
      "TOKEN 2023-11-08 00:41:08.503439  \n",
      "TOKEN 2023-11-08 00:41:08.525482 4\n",
      "TOKEN 2023-11-08 00:41:08.545014  *\n",
      "TOKEN 2023-11-08 00:41:08.565014  \n",
      "TOKEN 2023-11-08 00:41:08.586018 2\n",
      "TOKEN 2023-11-08 00:41:08.608051  =\n",
      "TOKEN 2023-11-08 00:41:08.626280  \n",
      "TOKEN 2023-11-08 00:41:08.648298 8\n",
      "TOKEN 2023-11-08 00:41:08.668288 .\n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:08.689303 Therefore\n",
      "TOKEN 2023-11-08 00:41:08.709301 ,\n",
      "TOKEN 2023-11-08 00:41:08.731329  (\n",
      "TOKEN 2023-11-08 00:41:08.751359 2\n",
      "TOKEN 2023-11-08 00:41:08.770082 +\n",
      "TOKEN 2023-11-08 00:41:08.790114 2\n",
      "TOKEN 2023-11-08 00:41:08.810887 )\n",
      "TOKEN 2023-11-08 00:41:08.832471  *\n",
      "TOKEN 2023-11-08 00:41:08.853169  \n",
      "TOKEN 2023-11-08 00:41:08.987921 2\n",
      "TOKEN 2023-11-08 00:41:08.988919  equals\n",
      "TOKEN 2023-11-08 00:41:08.989918  \n",
      "TOKEN 2023-11-08 00:41:08.990918 8\n",
      "TOKEN 2023-11-08 00:41:08.990918 .\n",
      "TOKEN 2023-11-08 00:41:08.991918 \n",
      "LLM_END 2023-11-08 00:41:08.992919 To solve the expression (2+2) * 2 step by step, we follow the order of operations, which is also known as PEMDAS (Parentheses, Exponents, Multiplication and Division from left to right, Addition and Subtraction from left to right).\n",
      "\n",
      "1. First, we evaluate the expression within the parentheses: (2+2) = 4.\n",
      "2. Now the expression becomes 4 * 2.\n",
      "3. Finally, we multiply 4 by 2: 4 * 2 = 8.\n",
      "\n",
      "Therefore, (2+2) * 2 equals 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='To solve the expression (2+2) * 2 step by step, we follow the order of operations, which is also known as PEMDAS (Parentheses, Exponents, Multiplication and Division from left to right, Addition and Subtraction from left to right).\\n\\n1. First, we evaluate the expression within the parentheses: (2+2) = 4.\\n2. Now the expression becomes 4 * 2.\\n3. Finally, we multiply 4 by 2: 4 * 2 = 8.\\n\\nTherefore, (2+2) * 2 equals 8.')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([HumanMessage(content=\"Tell me what is (2+2) * 2. Think step by step\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_START 2023-11-08 00:41:09.003494 human: Tell me what is (2+2) * 2. Think step by step\n",
      "_generate True\n",
      "_completion_with_retry {'messages': [{'role': 'user', 'content': 'Tell me what is (2+2) * 2. Think step by step'}], 'model': 'gpt-3.5-turbo', 'request_timeout': None, 'max_tokens': None, 'stream': True, 'n': 1, 'temperature': 0.7, 'api_key': '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', 'api_base': '', 'organization': ''}\n",
      "TOKEN 2023-11-08 00:41:09.959764 \n",
      "TOKEN 2023-11-08 00:41:09.961765 To\n",
      "TOKEN 2023-11-08 00:41:09.962765  solve\n",
      "TOKEN 2023-11-08 00:41:09.970764  (\n",
      "TOKEN 2023-11-08 00:41:09.988318 2\n",
      "TOKEN 2023-11-08 00:41:10.007123 +\n",
      "TOKEN 2023-11-08 00:41:10.045120 2\n",
      "TOKEN 2023-11-08 00:41:10.088147 )\n",
      "TOKEN 2023-11-08 00:41:10.101725  *\n",
      "TOKEN 2023-11-08 00:41:10.115172  \n",
      "TOKEN 2023-11-08 00:41:10.132421 2\n",
      "TOKEN 2023-11-08 00:41:10.153958  step\n",
      "TOKEN 2023-11-08 00:41:10.172337  by\n",
      "TOKEN 2023-11-08 00:41:10.193357  step\n",
      "TOKEN 2023-11-08 00:41:10.214199 ,\n",
      "TOKEN 2023-11-08 00:41:10.237961  follow\n",
      "TOKEN 2023-11-08 00:41:10.265967  the\n",
      "TOKEN 2023-11-08 00:41:10.274997  order\n",
      "TOKEN 2023-11-08 00:41:10.293116  of\n",
      "TOKEN 2023-11-08 00:41:10.311681  operations\n",
      "TOKEN 2023-11-08 00:41:10.331710 ,\n",
      "TOKEN 2023-11-08 00:41:10.363323  which\n",
      "TOKEN 2023-11-08 00:41:10.364323  is\n",
      "TOKEN 2023-11-08 00:41:10.390141  commonly\n",
      "TOKEN 2023-11-08 00:41:10.399141  known\n",
      "TOKEN 2023-11-08 00:41:10.424172  as\n",
      "TOKEN 2023-11-08 00:41:10.444122  PEM\n",
      "TOKEN 2023-11-08 00:41:10.460151 D\n",
      "TOKEN 2023-11-08 00:41:10.481832 AS\n",
      "TOKEN 2023-11-08 00:41:10.514213  (\n",
      "TOKEN 2023-11-08 00:41:10.526711 Paren\n",
      "TOKEN 2023-11-08 00:41:10.536715 theses\n",
      "TOKEN 2023-11-08 00:41:10.547130 ,\n",
      "TOKEN 2023-11-08 00:41:10.565522  Ex\n",
      "TOKEN 2023-11-08 00:41:10.621985 ponents\n",
      "TOKEN 2023-11-08 00:41:10.628001 ,\n",
      "TOKEN 2023-11-08 00:41:10.648917  Multip\n",
      "TOKEN 2023-11-08 00:41:10.666728 lication\n",
      "TOKEN 2023-11-08 00:41:10.689288  and\n",
      "TOKEN 2023-11-08 00:41:10.708073  Division\n",
      "TOKEN 2023-11-08 00:41:10.730100 ,\n",
      "TOKEN 2023-11-08 00:41:10.746628  and\n",
      "TOKEN 2023-11-08 00:41:10.785363  Addition\n",
      "TOKEN 2023-11-08 00:41:10.798363  and\n",
      "TOKEN 2023-11-08 00:41:10.804507  Sub\n",
      "TOKEN 2023-11-08 00:41:10.822755 traction\n",
      "TOKEN 2023-11-08 00:41:10.864823 ):\n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:10.875417 Step\n",
      "TOKEN 2023-11-08 00:41:10.881417  \n",
      "TOKEN 2023-11-08 00:41:10.909520 1\n",
      "TOKEN 2023-11-08 00:41:10.946385 :\n",
      "TOKEN 2023-11-08 00:41:10.971417  Simpl\n",
      "TOKEN 2023-11-08 00:41:10.979988 ify\n",
      "TOKEN 2023-11-08 00:41:10.999468  inside\n",
      "TOKEN 2023-11-08 00:41:11.023545  the\n",
      "TOKEN 2023-11-08 00:41:11.037541  parentheses\n",
      "TOKEN 2023-11-08 00:41:11.057915 \n",
      "\n",
      "TOKEN 2023-11-08 00:41:11.077249 (\n",
      "TOKEN 2023-11-08 00:41:11.094248 2\n",
      "TOKEN 2023-11-08 00:41:11.114670 +\n",
      "TOKEN 2023-11-08 00:41:11.152011 2\n",
      "TOKEN 2023-11-08 00:41:11.161083 )\n",
      "TOKEN 2023-11-08 00:41:11.177234  =\n",
      "TOKEN 2023-11-08 00:41:11.184488  \n",
      "TOKEN 2023-11-08 00:41:11.208166 4\n",
      "TOKEN 2023-11-08 00:41:11.230008 \n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:11.276698 Step\n",
      "TOKEN 2023-11-08 00:41:11.277835  \n",
      "TOKEN 2023-11-08 00:41:11.289845 2\n",
      "TOKEN 2023-11-08 00:41:11.311022 :\n",
      "TOKEN 2023-11-08 00:41:11.327029  Multiply\n",
      "TOKEN 2023-11-08 00:41:11.347043 \n",
      "\n",
      "TOKEN 2023-11-08 00:41:11.364059 4\n",
      "TOKEN 2023-11-08 00:41:11.383067  *\n",
      "TOKEN 2023-11-08 00:41:11.403177  \n",
      "TOKEN 2023-11-08 00:41:11.420206 2\n",
      "TOKEN 2023-11-08 00:41:11.447218  =\n",
      "TOKEN 2023-11-08 00:41:11.461261  \n",
      "TOKEN 2023-11-08 00:41:11.479359 8\n",
      "TOKEN 2023-11-08 00:41:11.503177 \n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:11.530030 Therefore\n",
      "TOKEN 2023-11-08 00:41:11.534039 ,\n",
      "TOKEN 2023-11-08 00:41:11.546710  (\n",
      "TOKEN 2023-11-08 00:41:11.560724 2\n",
      "TOKEN 2023-11-08 00:41:11.578757 +\n",
      "TOKEN 2023-11-08 00:41:11.593225 2\n",
      "TOKEN 2023-11-08 00:41:11.609989 )\n",
      "TOKEN 2023-11-08 00:41:11.628187  *\n",
      "TOKEN 2023-11-08 00:41:11.683096  \n",
      "TOKEN 2023-11-08 00:41:11.692096 2\n",
      "TOKEN 2023-11-08 00:41:11.697099  equals\n",
      "TOKEN 2023-11-08 00:41:11.719128  \n",
      "TOKEN 2023-11-08 00:41:11.728259 8\n",
      "TOKEN 2023-11-08 00:41:11.735260 .\n",
      "TOKEN 2023-11-08 00:41:11.747889 \n",
      "LLM_END 2023-11-08 00:41:11.749911 To solve (2+2) * 2 step by step, follow the order of operations, which is commonly known as PEMDAS (Parentheses, Exponents, Multiplication and Division, and Addition and Subtraction):\n",
      "\n",
      "Step 1: Simplify inside the parentheses\n",
      "(2+2) = 4\n",
      "\n",
      "Step 2: Multiply\n",
      "4 * 2 = 8\n",
      "\n",
      "Therefore, (2+2) * 2 equals 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='To solve (2+2) * 2 step by step, follow the order of operations, which is commonly known as PEMDAS (Parentheses, Exponents, Multiplication and Division, and Addition and Subtraction):\\n\\nStep 1: Simplify inside the parentheses\\n(2+2) = 4\\n\\nStep 2: Multiply\\n4 * 2 = 8\\n\\nTherefore, (2+2) * 2 equals 8.')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"Tell me what is (2+2) * 2. Think step by step\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_START 2023-11-08 00:41:11.758682 human: Tell me what is (2+2) * 2. Think step by step\n",
      "_agenerate True\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.518859 \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.519859 Sure\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.538678 !\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.550300  Let\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.583776 's\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.583776  break\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.608192  it\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.641191  down\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.686572  step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.727154  by\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.750243  step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.764562 :\n",
      "\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.784176 1\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.803259 .\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.822195  First\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.845147 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.860971  we\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.880144  evaluate\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.898157  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.916449  expression\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.938944  inside\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.952288  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.969185  parentheses\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:12.987330 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.004295  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.022268 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.050197  +\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.068561  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.088273 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.106380  =\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.126289  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.145587 4\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.164914 .\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.181885 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.198184 .\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.215189  Next\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.243209 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.255294  we\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.266304  multiply\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.283344  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.300718  result\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.451302  from\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.460192  step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.461313  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.464321 1\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.465324  by\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.468323  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.472322 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.473323 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.473323  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.475323 4\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.488400  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.505404  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.523440 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.540194  =\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.562279  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.580443 8\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.610539 .\n",
      "\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.636568 Therefore\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.641305 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.658915  (\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.677227 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.694425 +\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.870122 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.870122 )\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.870122  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.870122  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.871044 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.871044  equals\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.871044  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.871044 8\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.871044 .\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:13.872044 \n",
      "LLM_END 2023-11-08 00:41:13.873044 Sure! Let's break it down step by step:\n",
      "\n",
      "1. First, we evaluate the expression inside the parentheses: 2 + 2 = 4.\n",
      "2. Next, we multiply the result from step 1 by 2: 4 * 2 = 8.\n",
      "\n",
      "Therefore, (2+2) * 2 equals 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Sure! Let's break it down step by step:\\n\\n1. First, we evaluate the expression inside the parentheses: 2 + 2 = 4.\\n2. Next, we multiply the result from step 1 by 2: 4 * 2 = 8.\\n\\nTherefore, (2+2) * 2 equals 8.\")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await model.ainvoke([HumanMessage(content=\"Tell me what is (2+2) * 2. Think step by step\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_START 2023-11-08 00:41:14.396746 human: Tell me what is (2+2) * 2. Think step by step\n",
      "_agenerate True\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.340708 \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.340708 Step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.349718  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.365845 1\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.382338 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.554115  Begin\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.554115  by\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.554115  calculating\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.555113  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.555113  sum\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.555113  within\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.555113  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.561268  parentheses\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.577818 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.599275  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.615054 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.636072  +\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.649242  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.685257 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.687538  =\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.720247  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.721252 4\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.727268 .\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.743536 Step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.758267  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.772409 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.789289 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.839859  Multiply\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.867868  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.877868  result\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.894430  from\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.908680  step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.927468  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.941252 1\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.957695  by\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.974547  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:15.991945 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.044744 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.057746  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.074519 4\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.090165  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.110561  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.122561 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.144465  =\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.161437  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.182450 8\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.194448 .\n",
      "\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.212531 Therefore\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.227763 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.242718  (\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.260680 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.275749  +\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.453863  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.453863 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.453863 )\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.453863  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.455305  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.455305 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.455305  equals\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.456316  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.456316 8\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.456316 .\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:16.458706 \n",
      "LLM_END 2023-11-08 00:41:16.458706 Step 1: Begin by calculating the sum within the parentheses: 2 + 2 = 4.\n",
      "Step 2: Multiply the result from step 1 by 2: 4 * 2 = 8.\n",
      "\n",
      "Therefore, (2 + 2) * 2 equals 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Step 1: Begin by calculating the sum within the parentheses: 2 + 2 = 4.\\nStep 2: Multiply the result from step 1 by 2: 4 * 2 = 8.\\n\\nTherefore, (2 + 2) * 2 equals 8.')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(template=\"Tell me what is (2+2) * 2. Think step by step\")\n",
    "])\n",
    "callback = AsyncFunctionalStyleChatCompletionHandler(_callback)\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, streaming=True)\n",
    "model.callbacks = [callback]\n",
    "\n",
    "chain = chat_prompt | model\n",
    "await chain.ainvoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_START 2023-11-08 00:50:39.622123 human: Tell me what is (2+2) * 2. Think step by step\n",
      "_agenerate True\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:39.985545 \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:39.986545 Step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:39.994259  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.011337 1\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.028513 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.046166  Evaluate\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.066659  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.083129  expression\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.131757  inside\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.166413  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.186396  parentheses\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.203276 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.223293  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.244810 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.275804  +\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.305873  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.309423 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.321509  =\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.343519  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.362174 4\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.380631 .\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.413375 Step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.423186  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.449484 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.464063 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.471063  Multiply\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.500926  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.525965  result\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.536985  from\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.554956  step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.572704  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.597116 1\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.610104  by\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.631187  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.651383 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.664376 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.683549  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.697385 4\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.723883  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.741393  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.768127 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.779881  =\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.793055  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.811979 8\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.835408 .\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.847423 Therefore\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.860434 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.881185  (\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.897370 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:40.915800  +\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.111450  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.112470 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.113262 )\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.113262  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.114282  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.114282 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.115282  =\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.115282  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.117271 8\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.117271 .\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:50:41.125281 \n",
      "LLM_END 2023-11-08 00:50:41.125281 Step 1: Evaluate the expression inside the parentheses: 2 + 2 = 4.\n",
      "Step 2: Multiply the result from step 1 by 2: 4 * 2 = 8.\n",
      "Therefore, (2 + 2) * 2 = 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Step 1: Evaluate the expression inside the parentheses: 2 + 2 = 4.\\nStep 2: Multiply the result from step 1 by 2: 4 * 2 = 8.\\nTherefore, (2 + 2) * 2 = 8.')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = TransformChain(\n",
    "    transform=lambda row: {\"datetime_str\": str(row[\"datetime\"])},\n",
    "    input_variables=[\"datetime\"],\n",
    "    output_variables=[\"datetime_str\"]\n",
    ")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(template=\"Tell me what is (2+2) * 2. Think step by step\")\n",
    "])\n",
    "callback = AsyncFunctionalStyleChatCompletionHandler(_callback)\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, streaming=True)\n",
    "model.callbacks = [callback]\n",
    "\n",
    "chain = ct | chat_prompt | model\n",
    "await chain.ainvoke({\"datetime\": datetime.now()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai_limiter import LimitAwaitChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_START 2023-11-08 00:41:34.474421 human: Tell me what is (2+2) * 2. Think step by step\n",
      "_agenerate True\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.703854 \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.703854 To\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.716244  solve\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.732884  (\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.749904 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.770632 +\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.786553 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.803639 )\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.820224  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.970458  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.971460 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.971460  step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.972462  by\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.972462  step\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.972462 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.972462  follow\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.972462  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.981462  order\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:35.989841  of\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.007589  operations\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.058706 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.123462  which\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.123462  is\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.130135  parentheses\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.139136 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.150174  ex\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.171585 ponents\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.187210 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.199627  multiplication\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.222486  and\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.243086  division\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.261435  (\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.282843 from\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.297494  left\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.318702  to\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.331486  right\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.349949 ),\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.367525  and\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.386713  addition\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.402449  and\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.419570  subtraction\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.436743  (\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.452313 from\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.467535  left\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.487546  to\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.499730  right\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.525474 ):\n",
      "\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.545543 1\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.562593 .\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.577447  Start\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.593652  with\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.609280  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.627289  parentheses\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.640065 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.662348  (\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.702374 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.717225 +\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.733631 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.750235 )\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.770576  =\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.785405  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.807460 4\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.821636 \n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.836126   \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.855625  Therefore\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.871736 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.888614  the\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.909428  expression\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.921870  becomes\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.939443  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.954463 4\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.979099  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:36.989116  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.012111 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.024602 .\n",
      "\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.040036 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.058809 .\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.072813  Multiply\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.091875 :\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.114460  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.126184 4\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.141650  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.159635  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.176358 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.193516  =\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.209684  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.228595 8\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.246778 \n",
      "\n",
      "\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.261799 H\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.277123 ence\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.293170 ,\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.308674  (\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.326174 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.345174 +\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.360174 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.376565 )\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.460899  *\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.460899  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.460899 2\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.461901  equals\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.462593  \n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.476967 8\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.512071 .\n",
      "run_manager= <langchain.callbacks.manager.AsyncCallbackManagerForLLMRun object> [<__main__.AsyncFunctionalStyleChatCompletionHandler object>]\n",
      "TOKEN 2023-11-08 00:41:37.512071 \n",
      "LLM_END 2023-11-08 00:41:37.513075 To solve (2+2) * 2 step by step, follow the order of operations, which is parentheses, exponents, multiplication and division (from left to right), and addition and subtraction (from left to right):\n",
      "\n",
      "1. Start with the parentheses: (2+2) = 4\n",
      "   Therefore, the expression becomes 4 * 2.\n",
      "\n",
      "2. Multiply: 4 * 2 = 8\n",
      "\n",
      "Hence, (2+2) * 2 equals 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='To solve (2+2) * 2 step by step, follow the order of operations, which is parentheses, exponents, multiplication and division (from left to right), and addition and subtraction (from left to right):\\n\\n1. Start with the parentheses: (2+2) = 4\\n   Therefore, the expression becomes 4 * 2.\\n\\n2. Multiply: 4 * 2 = 8\\n\\nHence, (2+2) * 2 equals 8.')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = TransformChain(\n",
    "    transform=lambda row: {\"datetime_str\": str(row[\"datetime\"])},\n",
    "    input_variables=[\"datetime\"],\n",
    "    output_variables=[\"datetime_str\"]\n",
    ")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(template=\"Tell me what is (2+2) * 2. Think step by step\")\n",
    "])\n",
    "callback = AsyncFunctionalStyleChatCompletionHandler(_callback)\n",
    "model = LimitAwaitChatOpenAI(chat_openai=ChatOpenAI(openai_api_key=OPENAI_API_KEY, streaming=True))\n",
    "model.callbacks = [callback]\n",
    "\n",
    "chain = ct | chat_prompt | model\n",
    "await chain.ainvoke({\"datetime\": datetime.now()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_START 2023-11-08 00:41:39.258279 human: Tell me what is (2+2) * 2. Think step by step\n",
      "_completion_with_retry {'messages': [{'role': 'user', 'content': 'Tell me what is (2+2) * 2. Think step by step'}], 'model': 'gpt-3.5-turbo', 'request_timeout': None, 'max_tokens': None, 'stream': True, 'n': 1, 'temperature': 0.7, 'api_key': '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', 'api_base': '', 'organization': ''}\n",
      "TOKEN 2023-11-08 00:41:39.562918 \n",
      "TOKEN 2023-11-08 00:41:39.564295 To\n",
      "TOKEN 2023-11-08 00:41:39.608966  solve\n",
      "TOKEN 2023-11-08 00:41:39.627989  the\n",
      "TOKEN 2023-11-08 00:41:39.662852  expression\n",
      "TOKEN 2023-11-08 00:41:39.674771  (\n",
      "TOKEN 2023-11-08 00:41:39.680761 2\n",
      "TOKEN 2023-11-08 00:41:39.697838 +\n",
      "TOKEN 2023-11-08 00:41:39.720067 2\n",
      "TOKEN 2023-11-08 00:41:39.729823 )\n",
      "TOKEN 2023-11-08 00:41:39.783780  *\n",
      "TOKEN 2023-11-08 00:41:39.797906  \n",
      "TOKEN 2023-11-08 00:41:39.817690 2\n",
      "TOKEN 2023-11-08 00:41:39.839778  step\n",
      "TOKEN 2023-11-08 00:41:39.856284  by\n",
      "TOKEN 2023-11-08 00:41:39.871762  step\n",
      "TOKEN 2023-11-08 00:41:39.890300 ,\n",
      "TOKEN 2023-11-08 00:41:39.908246  we\n",
      "TOKEN 2023-11-08 00:41:39.927238  follow\n",
      "TOKEN 2023-11-08 00:41:39.946237  the\n",
      "TOKEN 2023-11-08 00:41:39.969789  order\n",
      "TOKEN 2023-11-08 00:41:39.988299  of\n",
      "TOKEN 2023-11-08 00:41:39.998776  operations\n",
      "TOKEN 2023-11-08 00:41:40.014854  (\n",
      "TOKEN 2023-11-08 00:41:40.084838 PE\n",
      "TOKEN 2023-11-08 00:41:40.085841 MD\n",
      "TOKEN 2023-11-08 00:41:40.086838 AS\n",
      "TOKEN 2023-11-08 00:41:40.087932 /B\n",
      "TOKEN 2023-11-08 00:41:40.094942 OD\n",
      "TOKEN 2023-11-08 00:41:40.110773 MAS\n",
      "TOKEN 2023-11-08 00:41:40.125773 ):\n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:40.143833 1\n",
      "TOKEN 2023-11-08 00:41:40.160463 .\n",
      "TOKEN 2023-11-08 00:41:40.179869  First\n",
      "TOKEN 2023-11-08 00:41:40.190096 ,\n",
      "TOKEN 2023-11-08 00:41:40.202095  we\n",
      "TOKEN 2023-11-08 00:41:40.222841  calculate\n",
      "TOKEN 2023-11-08 00:41:40.243867  the\n",
      "TOKEN 2023-11-08 00:41:40.259775  sum\n",
      "TOKEN 2023-11-08 00:41:40.281902  inside\n",
      "TOKEN 2023-11-08 00:41:40.295438  the\n",
      "TOKEN 2023-11-08 00:41:40.315806  parentheses\n",
      "TOKEN 2023-11-08 00:41:40.330487 :\n",
      "TOKEN 2023-11-08 00:41:40.348641  \n",
      "TOKEN 2023-11-08 00:41:40.363846 2\n",
      "TOKEN 2023-11-08 00:41:40.379873  +\n",
      "TOKEN 2023-11-08 00:41:40.394736  \n",
      "TOKEN 2023-11-08 00:41:40.427345 2\n",
      "TOKEN 2023-11-08 00:41:40.438346  equals\n",
      "TOKEN 2023-11-08 00:41:40.448085  \n",
      "TOKEN 2023-11-08 00:41:40.455477 4\n",
      "TOKEN 2023-11-08 00:41:40.487483 .\n",
      "\n",
      "TOKEN 2023-11-08 00:41:40.495228   \n",
      "TOKEN 2023-11-08 00:41:40.508015  The\n",
      "TOKEN 2023-11-08 00:41:40.527027  expression\n",
      "TOKEN 2023-11-08 00:41:40.540045  becomes\n",
      "TOKEN 2023-11-08 00:41:40.560845  \n",
      "TOKEN 2023-11-08 00:41:40.596586 4\n",
      "TOKEN 2023-11-08 00:41:40.607576  *\n",
      "TOKEN 2023-11-08 00:41:40.622646  \n",
      "TOKEN 2023-11-08 00:41:40.638343 2\n",
      "TOKEN 2023-11-08 00:41:40.660368 .\n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:40.674842 2\n",
      "TOKEN 2023-11-08 00:41:40.692850 .\n",
      "TOKEN 2023-11-08 00:41:40.705353  Next\n",
      "TOKEN 2023-11-08 00:41:40.720952 ,\n",
      "TOKEN 2023-11-08 00:41:40.744702  we\n",
      "TOKEN 2023-11-08 00:41:40.755701  perform\n",
      "TOKEN 2023-11-08 00:41:40.772662  the\n",
      "TOKEN 2023-11-08 00:41:40.788801  multiplication\n",
      "TOKEN 2023-11-08 00:41:40.801831 :\n",
      "TOKEN 2023-11-08 00:41:40.822664  \n",
      "TOKEN 2023-11-08 00:41:40.836917 4\n",
      "TOKEN 2023-11-08 00:41:40.851926  *\n",
      "TOKEN 2023-11-08 00:41:40.874781  \n",
      "TOKEN 2023-11-08 00:41:40.884683 2\n",
      "TOKEN 2023-11-08 00:41:40.905256  equals\n",
      "TOKEN 2023-11-08 00:41:40.917840  \n",
      "TOKEN 2023-11-08 00:41:40.937609 8\n",
      "TOKEN 2023-11-08 00:41:40.952724 .\n",
      "\n",
      "\n",
      "TOKEN 2023-11-08 00:41:40.970727 Therefore\n",
      "TOKEN 2023-11-08 00:41:40.980515 ,\n",
      "TOKEN 2023-11-08 00:41:41.006347  the\n",
      "TOKEN 2023-11-08 00:41:41.024669  answer\n",
      "TOKEN 2023-11-08 00:41:41.081048  to\n",
      "TOKEN 2023-11-08 00:41:41.108872  (\n",
      "TOKEN 2023-11-08 00:41:41.182739 2\n",
      "TOKEN 2023-11-08 00:41:41.198772 +\n",
      "TOKEN 2023-11-08 00:41:41.211795 2\n",
      "TOKEN 2023-11-08 00:41:41.224861 )\n",
      "TOKEN 2023-11-08 00:41:41.238649  *\n",
      "TOKEN 2023-11-08 00:41:41.250920  \n",
      "TOKEN 2023-11-08 00:41:41.263921 2\n",
      "TOKEN 2023-11-08 00:41:41.270265  is\n",
      "TOKEN 2023-11-08 00:41:41.277277  \n",
      "TOKEN 2023-11-08 00:41:41.286683 8\n",
      "TOKEN 2023-11-08 00:41:41.396917 .\n",
      "TOKEN 2023-11-08 00:41:41.415963 \n",
      "LLM_END 2023-11-08 00:41:41.415963 To solve the expression (2+2) * 2 step by step, we follow the order of operations (PEMDAS/BODMAS):\n",
      "\n",
      "1. First, we calculate the sum inside the parentheses: 2 + 2 equals 4.\n",
      "   The expression becomes 4 * 2.\n",
      "\n",
      "2. Next, we perform the multiplication: 4 * 2 equals 8.\n",
      "\n",
      "Therefore, the answer to (2+2) * 2 is 8.\n"
     ]
    }
   ],
   "source": [
    "async def _callback(event: LLMEventType, time: datetime, text: str) -> None:\n",
    "    print(f\"{event.value} {time} {text}\")\n",
    "\n",
    "\n",
    "callback = AsyncFunctionalStyleChatCompletionHandler(_callback)\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, streaming=True)\n",
    "model.callbacks = [callback]\n",
    "for token in model.stream([HumanMessage(content=\"Tell me what is (2+2) * 2. Think step by step\")]):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
