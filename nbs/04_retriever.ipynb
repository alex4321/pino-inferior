{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from typing import List, Set, Dict, Callable, Tuple, Union\n",
    "import hashlib\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.embeddings import Embeddings\n",
    "from langchain.vectorstores import VectorStore\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.ext.asyncio import AsyncEngine, AsyncSession\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "from pino_inferior.core import OPENAI_API_KEY, VECTOR_DB, VECTOR_DB_PARAMS, MEMORY_PARAMS\n",
    "from pino_inferior.models import aengine, ParagraphMemoryRecord\n",
    "from datetime import datetime\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "from langchain.chains import TransformChain\n",
    "import pandas as pd\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "TEXT_HASH_COLUMN = \"ParagraphHash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def md5string(text: str) -> str:\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ParagraphSplitter:\n",
    "    def split_text(self, text: str) -> List[Document]:\n",
    "        return [\n",
    "            Document(page_content=item, metadata={TEXT_HASH_COLUMN: f\"{md5string(item)}\"})\n",
    "            for item in text.split(\"\\n\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class SentenceSplitter:\n",
    "    def __init__(self):\n",
    "        self.separators=[\"\\.\\s\", \"\\?\", \"\\!\"]\n",
    "    \n",
    "    def _split_rest_separators(self, text: str, separators: List[str]) -> List[Document]:\n",
    "        if len(separators) == 0:\n",
    "            return [Document(page_content=text, metadata={})]\n",
    "        current_separator = separators[0]\n",
    "        next_separators = separators[1:]\n",
    "        result = []\n",
    "        for item in re.split(current_separator, text):\n",
    "            result += self._split_rest_separators(item, next_separators)\n",
    "        return result\n",
    "\n",
    "    def split_text(self, text: str) -> List[Document]:\n",
    "        return self._split_rest_separators(text, self.separators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SequentialSplitter:\n",
    "    def __init__(self, splitters: list) -> None:\n",
    "        self.splitters = splitters\n",
    "\n",
    "    def _split_inner(self, text: str, rest_splitters: list) -> List[Document]:\n",
    "        if len(rest_splitters) == 0:\n",
    "            return [Document(page_content=text, metadata={})]\n",
    "        current_splitter = rest_splitters[0]\n",
    "        next_splitters = rest_splitters[1:]\n",
    "        result = []\n",
    "        for item in current_splitter.split_text(text):\n",
    "            if isinstance(item, str):\n",
    "                item = Document(page_content=item, metadata={})\n",
    "            metadata = item.metadata\n",
    "            for record in self._split_inner(item.page_content, next_splitters):\n",
    "                result.append(Document(\n",
    "                    page_content=record.page_content,\n",
    "                    metadata=dict(metadata, **record.metadata)\n",
    "                ))\n",
    "        return result\n",
    "\n",
    "    def split_text(self, text: str) -> List[Document]:\n",
    "        return self._split_inner(text, self.splitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def _remove_known_paragraphs(session: AsyncSession, paragraphs: List[Document]) -> List[Document]:\n",
    "    hashes = set()\n",
    "    for document in paragraphs:\n",
    "        assert TEXT_HASH_COLUMN in document.metadata\n",
    "        hash = document.metadata[TEXT_HASH_COLUMN]\n",
    "        hashes.add(hash)\n",
    "    sql_query = select(ParagraphMemoryRecord).filter(\n",
    "        ParagraphMemoryRecord.md5.in_(hashes)\n",
    "    )\n",
    "    sql_search = await session.scalars(sql_query)\n",
    "    blacklisted_pairs = set()\n",
    "    for record in sql_search:\n",
    "        blacklisted_pairs.add((record.md5, record.text))\n",
    "    result = []\n",
    "    for document in paragraphs:\n",
    "        pair = (document.metadata[TEXT_HASH_COLUMN], document.page_content)\n",
    "        if pair not in blacklisted_pairs:\n",
    "            result.append(document)\n",
    "            blacklisted_pairs.add(pair)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def _store_paragraphs(documents_paragraphs: List[Document],\n",
    "                            sentence_splitter: SentenceSplitter,\n",
    "                            engine: AsyncEngine,\n",
    "                            vectorstore: VectorStore):\n",
    "    \n",
    "    def _prepare_sentence_documents(text: str, metadata: dict) -> List[Document]:\n",
    "        result = []\n",
    "        for item in sentence_splitter.split_text(document.page_content):\n",
    "            item_metadata = dict(**metadata)\n",
    "            item_text_full = \"\"\n",
    "            for key in metadata:\n",
    "                if key == TEXT_HASH_COLUMN:\n",
    "                    continue\n",
    "                item_text_full = f\"{item_text_full} : {metadata[key]}\"\n",
    "            item_text_full = f\"{item_text_full} : {item.page_content}\"\n",
    "            item_text_full = item_text_full.strip(\" :\")\n",
    "            item_metadata[\"_text\"] = text\n",
    "            result.append(Document(\n",
    "                page_content=item_text_full,\n",
    "                metadata=item_metadata,\n",
    "            ))\n",
    "        return result\n",
    "\n",
    "    sentences_to_add = []\n",
    "    assert isinstance(engine, AsyncEngine)\n",
    "    async with AsyncSession(engine) as session:\n",
    "        async with session.begin():\n",
    "            documents_paragraphs = await _remove_known_paragraphs(session,\n",
    "                                                                  documents_paragraphs)\n",
    "            records = []\n",
    "            for document in documents_paragraphs:\n",
    "                assert TEXT_HASH_COLUMN in document.metadata\n",
    "                hash = document.metadata[TEXT_HASH_COLUMN]\n",
    "                records.append(\n",
    "                    ParagraphMemoryRecord(\n",
    "                        text=document.page_content,\n",
    "                        meta=document.metadata,\n",
    "                        md5=hash,\n",
    "                        created_at=datetime.now()\n",
    "                    )\n",
    "                )\n",
    "                sentences_to_add += _prepare_sentence_documents(\n",
    "                    document.page_content,\n",
    "                    metadata=document.metadata,\n",
    "                )\n",
    "            \n",
    "            session.add_all(records)\n",
    "        if sentences_to_add:\n",
    "            vectorstore.add_documents(sentences_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def _get_paragraphs(sentence_vector_search_document_scores: List[Tuple[Document, float]], engine: Engine) -> \\\n",
    "    List[Tuple[ParagraphMemoryRecord, float]]:\n",
    "    async with AsyncSession(engine, expire_on_commit=False) as session:\n",
    "        def _get_hashes_to_search(sentence_vector_search: List[Document]) -> Set[str]:\n",
    "            parapraph_hashes = set()\n",
    "            for item in sentence_vector_search:\n",
    "                parapraph_hashes.add(item.metadata[TEXT_HASH_COLUMN])\n",
    "            return parapraph_hashes\n",
    "        \n",
    "        async def _extract_paragraphs_by_hashes(hashes: Set[str]) -> Dict[str, List[ParagraphMemoryRecord]]:\n",
    "            hash_to_paragraphs = {}\n",
    "            async with session.begin():\n",
    "                sql_query = select(ParagraphMemoryRecord).filter(\n",
    "                    ParagraphMemoryRecord.md5.in_(hashes)\n",
    "                )\n",
    "                sql_search = await session.scalars(sql_query)\n",
    "                for record in sql_search:\n",
    "                    if record.md5 not in hash_to_paragraphs:\n",
    "                        hash_to_paragraphs[record.md5] = []\n",
    "                    hash_to_paragraphs[record.md5].append(record)\n",
    "            return hash_to_paragraphs\n",
    "        \n",
    "        def _filter_paragraphs_by_metadata(sentence_vector_search: List[Document],\n",
    "                                           hash2paragraph: Dict[str, List[ParagraphMemoryRecord]]) \\\n",
    "                                           -> List[List[ParagraphMemoryRecord]]:\n",
    "            records_meta_found = []\n",
    "            for item in sentence_vector_search:\n",
    "                item_meta = item.metadata\n",
    "                item_meta_keys = set(item_meta)\n",
    "                potential_findings = hash2paragraph[item.metadata[TEXT_HASH_COLUMN]]\n",
    "                found = []\n",
    "                for record in potential_findings:\n",
    "                    record_meta = record.meta\n",
    "                    common_meta_keys = item_meta_keys & set(record_meta)\n",
    "                    item_common_meta = {key: item_meta[key] for key in common_meta_keys}\n",
    "                    record_common_meta = {key: record_meta[key] for key in common_meta_keys}\n",
    "                    if item_common_meta == record_common_meta:\n",
    "                        found.append(record)\n",
    "                records_meta_found.append(found)\n",
    "            return records_meta_found\n",
    "        \n",
    "        def _filter_paragraphs_by_text(sentence_vector_search: List[Document],\n",
    "                                    paragraphs: List[List[ParagraphMemoryRecord]]) \\\n",
    "            -> List[ParagraphMemoryRecord]:\n",
    "            result = []\n",
    "            for item, item_records_meta_found in zip(sentence_vector_search, paragraphs):\n",
    "                found = None\n",
    "                for record in item_records_meta_found:\n",
    "                    if item.metadata[\"_text\"] in record.text:\n",
    "                        found = record\n",
    "                        break\n",
    "                assert found is not None\n",
    "                result.append(found)\n",
    "            return result\n",
    "        \n",
    "        sentence_vector_search = [\n",
    "            document\n",
    "            for document, _ in sentence_vector_search_document_scores\n",
    "        ]\n",
    "        sentence_vector_scores = [\n",
    "            score\n",
    "            for _, score in sentence_vector_search_document_scores\n",
    "        ]\n",
    "        hashes = _get_hashes_to_search(sentence_vector_search)\n",
    "        hash2paragraph = await _extract_paragraphs_by_hashes(hashes)\n",
    "        paragraphs_meta_cleaned = _filter_paragraphs_by_metadata(sentence_vector_search, hash2paragraph)\n",
    "        paragraphs_text_cleaned = _filter_paragraphs_by_text(sentence_vector_search, paragraphs_meta_cleaned)\n",
    "        return [\n",
    "            (item, score)\n",
    "            for item, score in zip(paragraphs_text_cleaned, sentence_vector_scores)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _unique_documents(documents: List[Tuple[ParagraphMemoryRecord, float]],\n",
    "                      score_processor: Callable[[ParagraphMemoryRecord, float], float]) -> \\\n",
    "    List[Tuple[ParagraphMemoryRecord, float]]:\n",
    "    documents_by_id = {\n",
    "        document.id: document\n",
    "        for document, _ in documents\n",
    "    }\n",
    "    records = []\n",
    "    for document, score in documents:\n",
    "        records.append({\"id\": document.id, \"score\": score, \"created_at\": document.created_at})\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df[\"score_processed\"] = [\n",
    "        score_processor(documents_by_id[row[\"id\"]], row[\"score\"])\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    if len(df) == 0:\n",
    "        return []\n",
    "    id2max_score = df.groupby(\"id\")[\"score_processed\"].max()\n",
    "    id2max_score = id2max_score.sort_values(ascending=False)\n",
    "    return [\n",
    "        (documents_by_id[doc_id], id2max_score[doc_id])\n",
    "        for doc_id in id2max_score.index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "INPUT_RETRIEVER_QUERY = \"query\"\n",
    "INTERMEDIATE_RETRIEVER_DOCUMENTS = \"documents\"\n",
    "OUTPUT_RETRIEVER_DOCUMENTS = \"documents_text\"\n",
    "\n",
    "BLACKLISTED_META_PROPERTIES = {TEXT_HASH_COLUMN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _no_score_processing(document: ParagraphMemoryRecord, score: float) -> float:\n",
    "    return score\n",
    "\n",
    "\n",
    "ScoreProcessing = Union[None, Callable[[ParagraphMemoryRecord, float], float]]\n",
    "\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, engine: AsyncEngine, vector_db: VectorStore, \\\n",
    "                 lower_score_is_better: bool,\n",
    "                 score_processing: ScoreProcessing = None,\n",
    "                 top_k_sentences: int = 50,\n",
    "                 top_k_paragraphs: int = 5) -> None:\n",
    "        self.engine = engine\n",
    "        self.vector_db = vector_db\n",
    "        self.lower_score_is_better = lower_score_is_better\n",
    "        self.sentence_splitter = SentenceSplitter()\n",
    "        self.score_processing = score_processing\n",
    "        self.top_k_sentences = top_k_sentences\n",
    "        self.top_k_paragraphs = top_k_paragraphs\n",
    "\n",
    "    def store(self, paragraphs: List[Document]) -> None:\n",
    "        asyncio.get_event_loop().run_until_complete(\n",
    "            self.astore(paragraphs)\n",
    "        )\n",
    "\n",
    "    async def astore(self, paragraphs: List[Document]) -> None:\n",
    "        await _store_paragraphs(\n",
    "            documents_paragraphs=paragraphs,\n",
    "            sentence_splitter=self.sentence_splitter,\n",
    "            engine=self.engine,\n",
    "            vectorstore=self.vector_db\n",
    "        )\n",
    "\n",
    "    def _process_scores(self, documents: List[Tuple[Document, float]]) -> List[Tuple[Document, float]]:\n",
    "        k = 1\n",
    "        if self.lower_score_is_better:\n",
    "            k = -1\n",
    "        return [\n",
    "            (doc, score * k)\n",
    "            for doc, score in documents\n",
    "        ]\n",
    "    \n",
    "    def _get_score_processing(self):\n",
    "        if self.score_processing:\n",
    "            score_processing = self.score_processing\n",
    "        else:\n",
    "            score_processing = _no_score_processing\n",
    "        return score_processing\n",
    "    \n",
    "    def retrieve(self, query: str) -> List[Tuple[ParagraphMemoryRecord, float]]:\n",
    "        return asyncio.get_event_loop().run_until_complete(\n",
    "            self.aretrieve(query)\n",
    "        )\n",
    "    \n",
    "    async def aretrieve(self, query: str) -> List[Tuple[ParagraphMemoryRecord, float]]:\n",
    "        score_processing = self._get_score_processing()\n",
    "        # TODO: Add proper async calls to Milvus\n",
    "        sentence_similarity_search = await asyncio.to_thread(\n",
    "            self.vector_db.similarity_search_with_score,\n",
    "            query,\n",
    "            k=self.top_k_sentences\n",
    "        )\n",
    "        sentence_similarity_search = self._process_scores(sentence_similarity_search)\n",
    "        \n",
    "        document_extraction = await _get_paragraphs(\n",
    "            sentence_similarity_search,\n",
    "            self.engine\n",
    "        )\n",
    "        documents = _unique_documents(document_extraction, score_processing)\n",
    "        documents = documents[:self.top_k_paragraphs]\n",
    "        return documents\n",
    "    \n",
    "    def build_retriever_chain(self) -> RunnableSequence:\n",
    "        def _retrieve_documents(row):\n",
    "            return {\n",
    "                INTERMEDIATE_RETRIEVER_DOCUMENTS: self.retrieve(row[INPUT_RETRIEVER_QUERY])\n",
    "            }\n",
    "        \n",
    "        async def _aretrieve_documents(row):\n",
    "            return {\n",
    "                INTERMEDIATE_RETRIEVER_DOCUMENTS: await self.aretrieve(row[INPUT_RETRIEVER_QUERY])\n",
    "            }\n",
    "        \n",
    "        def _stringify_documents(row):\n",
    "            documents: List[Tuple[ParagraphMemoryRecord, float]] = row[INTERMEDIATE_RETRIEVER_DOCUMENTS]\n",
    "            records = []\n",
    "            for doc, _ in documents:\n",
    "                record = {}\n",
    "                record[\"text\"] = doc.text\n",
    "                record[\"meta\"] = \"\\n\\n\".join([\n",
    "                    f\"# {property_name} : {value}\"\n",
    "                    for property_name, value in doc.meta.items()\n",
    "                    if property_name not in BLACKLISTED_META_PROPERTIES\n",
    "                ])\n",
    "                records.append(record)\n",
    "            df = pd.DataFrame.from_records(records)\n",
    "            joined_paragraphs = []\n",
    "            if len(df) > 0:\n",
    "                for meta_text, sub_df in df.groupby(\"meta\"):\n",
    "                    paragraphs_joined_text = \"\\n\\n\".join(sub_df[\"text\"])\n",
    "                    meta_joined_text = f\"{meta_text}\\n\\n{paragraphs_joined_text}\"\n",
    "                    joined_paragraphs.append(meta_joined_text)\n",
    "            joined_text = \"\\n\\n\".join(joined_paragraphs)\n",
    "            return {\n",
    "                OUTPUT_RETRIEVER_DOCUMENTS: joined_text,\n",
    "            }\n",
    "        \n",
    "        async def _astringify_documents(row):\n",
    "            return _stringify_documents(row)\n",
    "        \n",
    "        retriever = TransformChain(\n",
    "            transform=_retrieve_documents,\n",
    "            atransform=_aretrieve_documents,\n",
    "            input_variables=[INPUT_RETRIEVER_QUERY],\n",
    "            output_variables=[INTERMEDIATE_RETRIEVER_DOCUMENTS],\n",
    "        )\n",
    "        stringifier = TransformChain(\n",
    "            transform=_stringify_documents,\n",
    "            atransform=_astringify_documents,\n",
    "            input_variables=[INTERMEDIATE_RETRIEVER_DOCUMENTS],\n",
    "            output_variables=[OUTPUT_RETRIEVER_DOCUMENTS]\n",
    "        )\n",
    "\n",
    "        return retriever | stringifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header1\"),\n",
    "    (\"##\", \"Header2\"),\n",
    "    (\"###\", \"Header3\"),\n",
    "]\n",
    "paragraph_splitter = SequentialSplitter(\n",
    "    [\n",
    "        MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on),\n",
    "        ParagraphSplitter(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = Memory(\n",
    "    engine=aengine,\n",
    "    vector_db=VECTOR_DB(\n",
    "        embedding_function=OpenAIEmbeddings(\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "            model=\"text-embedding-ada-002\",\n",
    "        ),\n",
    "        **VECTOR_DB_PARAMS\n",
    "    ),\n",
    "    **MEMORY_PARAMS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = \"\"\"\n",
    "# Intro (Markdown)\n",
    "\n",
    "## History \n",
    "\n",
    " Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9] \n",
    "\n",
    " Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files. \n",
    "\n",
    " ## Rise and divergence \n",
    "\n",
    " As Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for additional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks. \n",
    "\n",
    " #### Standardization \n",
    "\n",
    " From 2012, a group of people, including Jeff Atwood and John MacFarlane, launched what Atwood characterised as a standardisation effort. \n",
    "\n",
    " ## Implementations \n",
    "\n",
    " Implementations of Markdown are available for over a dozen programming languages.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = paragraph_splitter.split_text(md)\n",
    "memory.store(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = paragraph_splitter.split_text(md)\n",
    "await memory.astore(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Intro (Markdown) : History : Markdown is a lightweight markup language for creating formatted text using a plain-text editor', metadata={'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': 'ad5266c9513a3189e91da32213ff39f0', '_text': 'Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  '}),\n",
       "  0.10908434471413686),\n",
       " (Document(page_content='Intro (Markdown) : History : Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.', metadata={'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': '517e576f0199fcb5aa3c445c068c2798', '_text': 'Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.'}),\n",
       "  0.12008241441102752),\n",
       " (Document(page_content='Intro (Markdown) : Implementations : Implementations of Markdown are available for over a dozen programming languages.', metadata={'Header1': 'Intro (Markdown)', 'Header2': 'Implementations', 'ParagraphHash': '537a1381db0f7f4e4faa6eca1803cbab', '_text': 'Implementations of Markdown are available for over a dozen programming languages.'}),\n",
       "  0.13279209292776417),\n",
       " (Document(page_content='Intro (Markdown) : History : John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]', metadata={'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': 'ad5266c9513a3189e91da32213ff39f0', '_text': 'Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  '}),\n",
       "  0.13908894563129082)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.vector_db.similarity_search_with_score(\n",
    "    \"What is Markdown?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Intro (Markdown) : History : Markdown is a lightweight markup language for creating formatted text using a plain-text editor', metadata={'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': 'ad5266c9513a3189e91da32213ff39f0', '_text': 'Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  '}),\n",
       "  0.8909156552858631),\n",
       " (Document(page_content='Intro (Markdown) : History : Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.', metadata={'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': '517e576f0199fcb5aa3c445c068c2798', '_text': 'Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.'}),\n",
       "  0.8799175855889725),\n",
       " (Document(page_content='Intro (Markdown) : Implementations : Implementations of Markdown are available for over a dozen programming languages.', metadata={'Header1': 'Intro (Markdown)', 'Header2': 'Implementations', 'ParagraphHash': '537a1381db0f7f4e4faa6eca1803cbab', '_text': 'Implementations of Markdown are available for over a dozen programming languages.'}),\n",
       "  0.8672079070722358),\n",
       " (Document(page_content='Intro (Markdown) : History : John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]', metadata={'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': 'ad5266c9513a3189e91da32213ff39f0', '_text': 'Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  '}),\n",
       "  0.8609110543687092)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.vector_db.similarity_search_with_relevance_scores(\n",
    "    \"What is Markdown?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11619521600035798 {'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': 'ad5266c9513a3189e91da32213ff39f0'} Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  \n",
      "-0.13007329792339872 {'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': '517e576f0199fcb5aa3c445c068c2798'} Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.\n",
      "-0.14362861759808 {'Header1': 'Intro (Markdown)', 'Header2': 'Implementations', 'ParagraphHash': '537a1381db0f7f4e4faa6eca1803cbab'} Implementations of Markdown are available for over a dozen programming languages.\n",
      "-0.16130232938640965 {'Header1': 'Intro (Markdown)', 'Header2': 'Rise and divergence', 'ParagraphHash': '214fcbad683380c0e212dc177fc57a1a'} As Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for additional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks.  \n",
      "-0.1934415680790389 {'Header1': 'Intro (Markdown)', 'Header2': 'Rise and divergence', 'ParagraphHash': 'c6ab5fb2f5a7ab8c9b1659a5c221ca17'} From 2012, a group of people, including Jeff Atwood and John MacFarlane, launched what Atwood characterised as a standardisation effort.\n"
     ]
    }
   ],
   "source": [
    "for doc, score in memory.retrieve(\"What is Markdown\"):\n",
    "    print(score, doc.meta, doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11619521600035798 {'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': 'ad5266c9513a3189e91da32213ff39f0'} Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  \n",
      "-0.13007329792339872 {'Header1': 'Intro (Markdown)', 'Header2': 'History', 'ParagraphHash': '517e576f0199fcb5aa3c445c068c2798'} Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.\n",
      "-0.14362861759808 {'Header1': 'Intro (Markdown)', 'Header2': 'Implementations', 'ParagraphHash': '537a1381db0f7f4e4faa6eca1803cbab'} Implementations of Markdown are available for over a dozen programming languages.\n",
      "-0.16130232938640965 {'Header1': 'Intro (Markdown)', 'Header2': 'Rise and divergence', 'ParagraphHash': '214fcbad683380c0e212dc177fc57a1a'} As Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for additional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks.  \n",
      "-0.1934415680790389 {'Header1': 'Intro (Markdown)', 'Header2': 'Rise and divergence', 'ParagraphHash': 'c6ab5fb2f5a7ab8c9b1659a5c221ca17'} From 2012, a group of people, including Jeff Atwood and John MacFarlane, launched what Atwood characterised as a standardisation effort.\n"
     ]
    }
   ],
   "source": [
    "for doc, score in (await memory.aretrieve(\"What is Markdown\")):\n",
    "    print(score, doc.meta, doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : History\n",
      "\n",
      "Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  \n",
      "\n",
      "Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.\n",
      "\n",
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : Implementations\n",
      "\n",
      "Implementations of Markdown are available for over a dozen programming languages.\n",
      "\n",
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : Rise and divergence\n",
      "\n",
      "As Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for additional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks.  \n",
      "\n",
      "From 2012, a group of people, including Jeff Atwood and John MacFarlane, launched what Atwood characterised as a standardisation effort.\n"
     ]
    }
   ],
   "source": [
    "retrieved_chain = memory.build_retriever_chain()\n",
    "\n",
    "print(retrieved_chain.invoke({INPUT_RETRIEVER_QUERY: \"What is Markdown\"})[OUTPUT_RETRIEVER_DOCUMENTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : History\n",
      "\n",
      "Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  \n",
      "\n",
      "Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.\n",
      "\n",
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : Implementations\n",
      "\n",
      "Implementations of Markdown are available for over a dozen programming languages.\n",
      "\n",
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : Rise and divergence\n",
      "\n",
      "As Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for additional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks.  \n",
      "\n",
      "#### Standardization  \n"
     ]
    }
   ],
   "source": [
    "print(retrieved_chain.invoke({INPUT_RETRIEVER_QUERY: \"Что такое Markdown\"})[OUTPUT_RETRIEVER_DOCUMENTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : History\n",
      "\n",
      "Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  \n",
      "\n",
      "Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.\n",
      "\n",
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : Implementations\n",
      "\n",
      "Implementations of Markdown are available for over a dozen programming languages.\n",
      "\n",
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : Rise and divergence\n",
      "\n",
      "As Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for additional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks.  \n",
      "\n",
      "From 2012, a group of people, including Jeff Atwood and John MacFarlane, launched what Atwood characterised as a standardisation effort.\n"
     ]
    }
   ],
   "source": [
    "print( (await retrieved_chain.ainvoke({INPUT_RETRIEVER_QUERY: \"What is Markdown\"}))[OUTPUT_RETRIEVER_DOCUMENTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : History\n",
      "\n",
      "Markdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber created Markdown in 2004 as a markup language that is appealing to human readers in its source code form.[9]  \n",
      "\n",
      "Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.\n",
      "\n",
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : Implementations\n",
      "\n",
      "Implementations of Markdown are available for over a dozen programming languages.\n",
      "\n",
      "# Header1 : Intro (Markdown)\n",
      "\n",
      "# Header2 : Rise and divergence\n",
      "\n",
      "As Markdown popularity grew rapidly, many Markdown implementations appeared, driven mostly by the need for additional features such as tables, footnotes, definition lists,[note 1] and Markdown inside HTML blocks.  \n",
      "\n",
      "#### Standardization  \n"
     ]
    }
   ],
   "source": [
    "print( (await retrieved_chain.ainvoke({INPUT_RETRIEVER_QUERY: \"Что такое Markdown\"}))[OUTPUT_RETRIEVER_DOCUMENTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex4321/mambaforge/envs/pino-inferior/lib/python3.11/site-packages/nbdev/export.py:54: UserWarning: Notebook '/mnt/hdd/Projects/pino-inferior1/nbs/07_agent.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n"
     ]
    }
   ],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
